{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language SQL processor \n",
    "### with HuggingFace's free, open source Inference API\n",
    "\n",
    "---\n",
    "\n",
    "Get a free Hugging Face Inference API Access token with [these instructions](https://huggingface.co/docs/hub/security-tokens).\n",
    "\n",
    "I use Hugging Face's [Zephyr 7B Beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) LLM. There are probably better ones, but this one is small? I think?\n Yale LILY lab's [Spider project](https://yale-lily.github.io/spider) has mapped out the best performing models. Of the available off-the-shelf LLMs, GPT-4 outperforms pretty much everyone elseâ€“ but alas I am a plebe without a paid OpenAI subscription.\n",
    "\n",
    "The default database is MySQL. To change, configure the uri in #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"...\"\n",
    "USER = \"...\"\n",
    "PWD = \"...\"\n",
    "HOST = \"...\"\n",
    "\n",
    "HUGGING_FACE_ACCESS_TOKEN = \"...\"\n",
    "\n",
    "QUESTION = \"How many orders were placed on september 10th, 2023?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False # change to True if you want to install the dependencies\n",
    "if install:\n",
    "    !pip install sqlalchemy\n",
    "    !pip install langchain\n",
    "    !pip install mysql-connector-python\n",
    "    !pip install huggingface_hub\n",
    "    !pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to MySQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from langchain.utilities import SQLDatabase\n",
    "\n",
    "db_uri = f\"mysql+mysqlconnector://{USER}:{PWD}@{HOST}/{DB_NAME}\"  # change this for other dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connect to Hugging Face Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGING_FACE_ACCESS_TOKEN\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get SQL response\n",
    "\n",
    "`create_sql_query_chain` does not create an agent (I don't think), but just a runnable 'chain' object that fills and runs [pre-engineered prompts](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/sql_database/prompt.py) against the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "sql_chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes like a minute\n",
    "\n",
    "sql_response = sql_chain.invoke({\"question\": QUESTION})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execute query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlalchemy connection for real\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_uri)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# execute the query, return as dataframe\n",
    "\n",
    "df = pd.read_sql_query(\n",
    "    sql = sql_response,\n",
    "    con = engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
